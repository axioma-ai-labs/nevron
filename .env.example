# ==============================================================================
# Nevron Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# Required: At minimum, set one LLM provider API key (e.g., OPENAI_API_KEY)
# ==============================================================================

# ==============================================================================
# General Settings
# ==============================================================================

# Environment: production, development, ci
ENVIRONMENT=development

# Project name
PROJECT_NAME=nevron-agent

# ==============================================================================
# LLM Provider Configuration
# ==============================================================================
# Choose ONE provider and set its API key. The provider determines which
# LLM backend is used for agent reasoning.

# LLM Provider: openai, anthropic, xai, deepseek, qwen, venice, llama
LLM_PROVIDER=openai

# --- OpenAI ---
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# --- Anthropic ---
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# --- xAI (Grok) ---
XAI_API_KEY=
XAI_MODEL=grok-2-latest

# --- DeepSeek ---
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_API_BASE_URL=https://api.deepseek.com

# --- Qwen ---
QWEN_API_KEY=
QWEN_MODEL=qwen-max
QWEN_API_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1

# --- Venice ---
VENICE_API_KEY=
VENICE_MODEL=llama-3.3-70b
VENICE_API_BASE_URL=https://api.venice.ai/api/v1

# --- Llama (various providers) ---
# Provider: ollama, fireworks, llama_api, openrouter, local
LLAMA_PROVIDER=ollama
LLAMA_MODEL_NAME=llama3-8b-8192
LLAMA_API_KEY=
LLAMA_MODEL_PATH=/path/to/your/local/llama/model
LLAMA_OLLAMA_URL=http://localhost:11434
LLAMA_FIREWORKS_URL=https://api.fireworks.ai/inference
LLAMA_API_BASE_URL=https://api.llama-api.com
LLAMA_OPENROUTER_URL=https://openrouter.ai/api/v1

# ==============================================================================
# Embedding Configuration
# ==============================================================================

# Embedding provider: openai, llama_local, llama_api
EMBEDDING_PROVIDER=openai

# For Llama embeddings
LLAMA_EMBEDDING_MODEL=llama3.1-8b
# Pooling type: NONE, MEAN, CLS, LAST, RANK
EMBEDDING_POOLING_TYPE=MEAN

# ==============================================================================
# Memory Configuration
# ==============================================================================

# Memory backend: chroma, qdrant
MEMORY_BACKEND_TYPE=chroma

# Memory collection name
MEMORY_COLLECTION_NAME=agent_memory

# ChromaDB settings (used when MEMORY_BACKEND_TYPE=chroma)
MEMORY_PERSIST_DIRECTORY=.chromadb

# Qdrant settings (used when MEMORY_BACKEND_TYPE=qdrant)
MEMORY_HOST=localhost
MEMORY_PORT=6333
MEMORY_VECTOR_SIZE=1536

# ==============================================================================
# Agent Configuration
# ==============================================================================

# Agent personality (how the agent behaves and responds)
AGENT_PERSONALITY=You are a helpful AI assistant. You analyze information and provide insights.

# Agent goal (what the agent is trying to achieve)
AGENT_GOAL=Help users by analyzing data and providing useful insights.

# Rest time between agent actions (seconds)
AGENT_REST_TIME=300

# ==============================================================================
# Integration Settings (Optional)
# ==============================================================================
# Configure only the integrations you need

# --- Twitter/X ---
TWITTER_API_KEY=
TWITTER_API_SECRET_KEY=
TWITTER_ACCESS_TOKEN=
TWITTER_ACCESS_TOKEN_SECRET=

# --- Telegram ---
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=

# --- Discord ---
DISCORD_BOT_TOKEN=
DISCORD_CHANNEL_ID=

# --- Slack ---
SLACK_BOT_TOKEN=
SLACK_APP_TOKEN=

# --- WhatsApp (Green API) ---
WHATSAPP_ID_INSTANCE=
WHATSAPP_API_TOKEN=

# --- GitHub ---
GITHUB_TOKEN=

# --- YouTube ---
YOUTUBE_API_KEY=
YOUTUBE_PLAYLIST_ID=

# --- Spotify ---
SPOTIFY_CLIENT_ID=
SPOTIFY_CLIENT_SECRET=
SPOTIFY_REDIRECT_URI=

# --- Shopify ---
SHOPIFY_API_KEY=
SHOPIFY_PASSWORD=
SHOPIFY_STORE_NAME=

# --- Lens Protocol ---
LENS_API_KEY=
LENS_PROFILE_ID=

# ==============================================================================
# Search & Research Tools (Optional)
# ==============================================================================

# --- Perplexity ---
PERPLEXITY_API_KEY=
PERPLEXITY_ENDPOINT=https://api.perplexity.ai/chat/completions
PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online

# --- Tavily ---
TAVILY_API_KEY=

# --- Coinstats ---
COINSTATS_API_KEY=

# --- Jina Reader ---
JINA_READER_API_KEY=
JINA_READER_TIMEOUT=30
JINA_READER_TOKEN_BUDGET=4000
JINA_SEARCH_WEBSITE=

# ==============================================================================
# MCP (Model Context Protocol) Settings
# ==============================================================================

# Enable MCP integration
MCP_ENABLED=true

# Path to MCP servers configuration file (YAML)
# MCP_CONFIG_FILE=./mcp_servers.yaml

# Auto-connect to MCP servers on startup
MCP_AUTO_CONNECT=true

# Reconnection settings
MCP_RECONNECT_ON_FAILURE=true
MCP_MAX_RECONNECT_ATTEMPTS=3
